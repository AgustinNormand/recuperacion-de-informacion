## Análisis de Texto
##### Fecha entrega: 25/03/2021

###### Normand Agustín

###### Legajo: 156649

Para la entrega del TP resuelto arme un único archivo comprimido (.tar.gz) y envielo a través del siguiente formulario:
https://forms.gle/enizkPdDeA25AotC7 el cual se encontrará habilitado hasta la fecha de entrega establecida.

Bibliografı́a sugerida: MIR [1] Capı́tulo 7, TOL [5] Capı́tulo 3, MAN [4] Capı́tulo 6, Grefenstette et al. [2], Ha et al. [3].

##### 1. Escriba un programa que realice análisis léxico sobre la colección RI-tknz-data. El programa debe recibir como parámetros el directorio donde se encuentran los documentos y un argumento que indica si se deben eliminar las palabras vacı́as (y en tal caso, el nombre del archivo que las contiene). Defina, además, una longitud mı́nima y máxima para los términos. Como salida, el programa debe generar:
##### a) Un archivo (terminos.txt) con la lista de términos a indexar (ordenado), su frecuencia en la colección y su DF (Document Frequency). Formato de salida: < termino > [ESP ] < CF > [ESP ] < DF >.
##### Ejemplo:
casa 238 3
perro 644 6
...
zorro 12 1

##### Respuesta:

Para resolver este ejercicio cree las siguientes clases:

* Document
* Collection
* Normalizer
* Tokenizer
* Exporter

Dichas clases se encuentran en el directorio ejercicio_1. Junto con el archivo emptywords.csv donde cargué las palabras vacías. Y además, también podemos encontrar los archivos de salida del programa: 

* terminos.txt
* estadisticas.txt
* frecuencias.txt

Para correr el programa, python3 tokenizer.py path_coleccion path_archivo_palabras_vacias

En caso de no querer utilizar un archivo de palabras vacias, simplemente correr python3 tokenizer.py path_coleccion

##### b) Un segundo archivo (estadisticas.txt) con los siguientes datos (un punto por lı́nea y separados por espacio cuando sean más de un valor) :

1) Cantidad de documentos procesados
2) Cantidad de tokens y términos extraı́dos
3) Promedio de tokens y términos de los documentos
4) Largo promedio de un término
5) Cantidad de tokens y términos del documento más corto y del más largo1
6) Cantidad de términos que aparecen sólo 1 vez en la colección

##### c) Un tercer archivo (frecuencias.txt, con un término y su CF por lı́nea) con:

1) La lista de los 10 términos más frecuentes y su CF (Collection Frequency)
2) La lista de los 10 términos menos frecuentes y su CF.




2. Tomando como base el programa anterior, escriba un segundo T okenizer que implemente los criterios del
artı́culo de Grefenstette y Tapanainen para definir qué es una “palabra” (o término) y cómo tratar números
y signos de puntuación. Además, extraiga en listas separadas utilizando en cada caso una función especı́fica.
a) Abreviaturas tal cual están escritas (por ejemplo, Dr., Lic., S.A., NASA, etc.)

Si quiero matchear abreviaturas como NASA, es inevitable que la expresión regular tambien matchee:

* JEFE
* FOTO
* SPAM
* UEFA
* AYER
* ANSA

Abreviaturas con 3 letras mayusculas:

* PDF
* AFA
* CIA
* UBA
* USB
* VIH
* HIV
* DNI
* OMS

No validas

* SON
* DEL
* MAS
* MIL
* LOS
* RIO

b) Direcciones de correo electrónico y URLs
c) Números (por ejemplo, cantidades, teléfonos)
d ) Nombres propios (por ejemplo, Villa Carlos Paz, Manuel Belgrano, etc.) y los trate como un único
token.
Genere y almacene la misma información que en el caso anterior.
<!---
3. A partir del programa del ejercicio 1, incluya un proceso de stemming 2 . Luego de modificar su programa,
corra nuevamente el proceso del ejercicio 1 y analice los cambios en la colección. ¿Qué implica este resultado?
Busque ejemplos de pares de términos que tienen la misma raı́z pero que el stemmer los trató diferente y
términos que son diferentes y se los trató igual.
4. Sobre la colección CISI3 , ejecute los stemmers de Porter y Lancaster provistos en el módulo nltk.stem.
Compare: cantidad de tokens resultantes, resultado 1 a 1 y tiempo de ejecución para toda la colección. Qué
conclusiones puede obtener de la ejecución de uno y otro?
5. Escriba un programa que realice la identificación del lenguaje de un texto a partir de un conjunto de
entrenamiento4 . Pruebe dos métodos sencillos:
a) Uno basado en la distribución de la frecuencia de las letras.
b) El segundo, basado en calcular la probabilidad de que una letra x preceda a una y (calcule una matriz
de probabilidades con todas las combinaciones).
Compare los resultados contra el módulo Python langdetect5 y la solución provista.
Propiedades del Texto6 .
6. En este ejercicio se propone verificar la predicción de ley de Zipf. Para ello, descargue desde Project Gu-
tenberg el texto del Quijote de Cervantes7 y escriba un programa que extraiga los términos y calcule sus
frecuencias (el programa debe generar la lista ordenada por frecuencia descencente). Calcule la curva de
ajuste utilizando la función Polyfit del módulo NymPy8 . Con los datos crudos y los estimados grafique en la
notebook ambas distribuciones (haga 2 gráficos, uno en escala lineal y otro en log-log). ¿Cómo se comporta
la predicción? ¿Qué conclusiones puede obtener?
7. Usando los datos del ejercicios anterior y de acuerdo a la ley de Zipf, calcule la proporción del total de
términos para aquellos que tienen frecuencia f = {100, 1000, 10000}. Verifique respecto de los valores reales.
¿Qué conclusión puede obtener?
8. Codifique un script que reciba como parámetro el nombre de un archivo de texto, tokenize y calcule y
escriba a un archivo los pares (#términos totales procesados, #términos únicos). Verifique en qué medida
satisface la ley de Heaps. Grafique en la notebook los ajustes variando los parámetros de la expresión. Puede
inicialmente probar con los archivos de los puntos anteriores.


Si no es ninguna expresion regular, lo paso por el filtro de longitud de caracteres.

REGULAR EXPR

Email
distanciapedenfermeria@gmail.com0351-4334028/4043

URL
http://www.youtube.comhttp://www.youtube.com
'http://www.kennedy.edu.ar/';//window.location.href
'http://csi.gstatic.com/csi');


Abrebiation de Dr. Lic. Mg.
Estero.
Estero.
Campos.
Vegas.
Porta.
Quinteros.
Sandes.
Grippo.

Abrebiation de etc.
dr.
dr.
dr.
dra.
prof.
ed.
pag.
(Estos están bastante bien, pero mezclados con basura.)

familia.
biopolitica.
exclusion.
filosofia.
estado.
nazismo.
amor.
muerte.
razón.
occidente.
(estos son fin de parrafos? tendría que ver si la palabra siguiente arranca con mayuscula)

Abrebiation ([A-Z]\.)
DyN.
VIH.
AIRES.-
DT.
HABANA.
MADRID.-
W.
W.
CIA.
W.
UBA.
AIRES.-
M.
C.
YAKARTA.-
IDESA.
SPAM.









Notas: 

* Las palabras vacias, siguen siendo tokens en el documento? O no son ni tokens ni terminos?

* Los documentos se procesan linea a linea. Nombre propio separado en 2 lineas?
Si las parseo, como me fijo los nombres propios? Ya lo pregunte

Lo del largo del termino, debería ser despues de haber normaliado, traducido, etc. Ya lo pregunte

academicasfcfmnfchficesipaudedainformesdepartamentosareascargosdedicacioncaracterinscripcionresolucion
Porque no se limito ese termino? Resuelto



Elegir longitud minima y maxima tokens, documentar porque esa decision.

Cantidad de terminos es cantidaad univoca de terminos? Sería como las claves del diccionario?

Promedio de terminos de los documentos? Sumo todas las frecuencias de terminos y las divido por la cantida de documentoss? O es la cantidad de claves del diccionario dividido la cantidad de documentos?












Quijote:
Elimine la primera parte en inglés, hasta el titulo.
-->



